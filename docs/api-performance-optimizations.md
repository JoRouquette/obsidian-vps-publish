# API Performance Optimizations

## Analyse de l'architecture actuelle

### Workflow actuel

1. **Plugin** ‚Üí compress + chunk ‚Üí envoie batches s√©quentiellement
2. **API** ‚Üí re√ßoit chunks ‚Üí assemble ‚Üí d√©compresse ‚Üí traite
3. Chaque batch est trait√© **s√©quentiellement** (attente de r√©ponse avant prochain batch)

### Goulots d'√©tranglement identifi√©s

#### 1. **Upload s√©quentiel des batches**

**Probl√®me** : Le plugin attend la r√©ponse de chaque batch avant d'envoyer le suivant.

**Impact** :

- Latency r√©seau multipli√©e par le nombre de batches
- Si 10 batches avec 200ms de latency r√©seau ‚Üí +2000ms de d√©lai incompressible

**Localisation** :

- `apps/obsidian-vps-publish/src/lib/infra/notes-uploader.adapter.ts:64-108`
- `apps/obsidian-vps-publish/src/lib/infra/assets-uploader.adapter.ts:98-145`

```typescript
// Actuel : s√©quentiel
for (const batch of batches) {
  const chunks = await this.chunkedUploadService.prepareUpload(uploadId, payload);
  await this.chunkedUploadService.uploadAll(chunks, uploader, ...);
  await yieldToEventLoop(); // Yield entre batches
}
```

#### 2. **Traitement synchrone c√¥t√© API**

**Probl√®me** : L'API traite chaque note individuellement de mani√®re synchrone dans le handler.

**Impact** :

- CPU bloqu√© pendant le rendering Markdown (co√ªteux)
- Pas de parall√©lisation possible des op√©rations I/O (write HTML, update manifest)

**Localisation** :

- `libs/core-application/src/lib/publishing/handlers/upload-notes.handler.ts:60-96`

```typescript
// Actuel : boucle for synchrone
for (const note of notes) {
  const bodyHtml = await this.markdownRenderer.render(note);
  const fullHtml = this.buildHtmlPage(note, bodyHtml);
  await contentStorage.save({ route, content: fullHtml, slug });
  published++;
}
```

#### 3. **Middleware chunked upload s√©quentiel**

**Probl√®me** : Les chunks sont r√©assembl√©s uniquement quand **tous** sont re√ßus.

**Impact** :

- M√©morisation de tous les chunks avant traitement (overhead m√©moire)
- Pas de traitement anticip√© possible

**Localisation** :

- `apps/node/src/infra/http/express/middleware/chunked-upload.middleware.ts:48-75`

## Solutions propos√©es

### Solution 1 : Upload parall√®le des batches (IMPACT √âLEV√â)

**Principe** : Uploader plusieurs batches en parall√®le avec concurrence contr√¥l√©e (ex: 3 simultan√©s).

**Avantages** :

- R√©duction drastique du temps d'upload (latency r√©seau divis√©e par le facteur de concurrence)
- Utilise mieux la bande passante disponible
- Facile √† impl√©menter avec les utilitaires existants (`ConcurrencyLimiter`)

**Impl√©mentation** :

```typescript
// Dans NotesUploaderAdapter.upload()
import { processWithControlledConcurrency } from '@core-application/utils/concurrency.util';

async upload(notes: PublishableNote[]): Promise<boolean> {
  const batches = batchByBytes(notes, this.maxBytesPerRequest, (batch) => ({ notes: batch }));

  this._logger.debug(
    `Uploading ${notes.length} notes in ${batches.length} batch(es) with concurrency=3`
  );

  let batchIndex = 0;
  const uploadBatch = async (batch: PublishableNote[]) => {
    batchIndex++;
    const uploadId = `notes-${this.sessionId}-${this.guidGenerator.generateGuid()}`;

    const payload = {
      notes: batch,
      ...(batchIndex === 1 && this.cleanupRules ? { cleanupRules: this.cleanupRules } : {}),
    };

    const chunks = await this.chunkedUploadService.prepareUpload(uploadId, payload);
    const uploader = new NoteChunkUploaderAdapter(this.sessionClient, this.sessionId);

    await this.chunkedUploadService.uploadAll(chunks, uploader, (current, total) => {
      this._logger.debug('Chunk upload progress', { uploadId, current, total });
    });

    this.advanceProgress(batch.length);
  };

  // Upload batches avec concurrence=3
  await processWithControlledConcurrency(
    batches,
    uploadBatch,
    3, // concurrency
    50, // yieldAfterN operations
    (current, total) => {
      this._logger.debug('Batch upload progress', { current, total });
    }
  );

  this._logger.debug('Successfully uploaded notes to session');
  return true;
}
```

**Impact estim√©** :

- Avec 10 batches et 200ms latency : **2000ms ‚Üí ~800ms** (gain ~60%)
- Avec 5 batches : **1000ms ‚Üí ~400ms** (gain ~60%)

**Risques** :

- Ordre d'arriv√©e des batches non garanti (mais l'API est stateless, pas de probl√®me)
- Pic de charge c√¥t√© API (limiter concurrency √† 3-5 max)

---

### Solution 2 : Traitement parall√®le c√¥t√© API handler (IMPACT MOYEN-√âLEV√â)

**Principe** : Parall√©liser le rendering Markdown + save HTML dans l'`UploadNotesHandler`.

**Avantages** :

- Utilise mieux les CPU multi-core c√¥t√© backend
- R√©duction du temps de traitement pour les gros batches
- Am√©liore le d√©bit (throughput)

**Impl√©mentation** :

```typescript
// Dans UploadNotesHandler.handle()
async handle(command: UploadNotesCommand): Promise<UploadNotesResult> {
  const { sessionId, notes } = command;
  const logger = this.logger?.child({ method: 'handle', sessionId });

  logger?.debug(`Starting parallel publishing of ${notes.length} notes`);

  // Traiter avec concurrence contr√¥l√©e
  const results = await Promise.allSettled(
    notes.map(async (note) => {
      const noteLogger = logger?.child({ noteId: note.noteId });

      // Render + save en parall√®le
      const bodyHtml = await this.markdownRenderer.render(note);
      const fullHtml = this.buildHtmlPage(note, bodyHtml);

      await contentStorage.save({
        route: note.routing.fullPath,
        content: fullHtml,
        slug: note.routing.slug,
      });

      noteLogger?.debug('Note published successfully');
      return note;
    })
  );

  // Agr√©ger les r√©sultats
  const succeeded: PublishableNote[] = [];
  const errors: { noteId: string; message: string }[] = [];

  results.forEach((result, idx) => {
    if (result.status === 'fulfilled') {
      succeeded.push(result.value);
    } else {
      errors.push({
        noteId: notes[idx].noteId,
        message: result.reason?.message ?? 'Unknown error',
      });
    }
  });

  // Update manifest (group√©)
  if (succeeded.length > 0) {
    const pages: ManifestPage[] = succeeded.map((n) => ({ ... }));
    await manifestStorage.upsertPages(pages);
  }

  return { sessionId, published: succeeded.length, errors };
}
```

**Impact estim√©** :

- Avec 50 notes et rendering √† 50ms/note : **2500ms ‚Üí ~600ms** (gain ~75% avec 4 cores)
- Avec 150 notes : **7500ms ‚Üí ~2000ms** (gain ~73%)

**Risques** :

- Pic de consommation CPU/m√©moire c√¥t√© backend
- Surcharge si markdown rendering est I/O-bound plut√¥t que CPU-bound
- **Solution** : Limiter concurrence avec `processWithControlledConcurrency(notes, processNote, 10)`

---

### Solution 3 : Streaming de r√©ponse API (IMPACT FAIBLE-MOYEN)

**Principe** : L'API renvoie un statut interm√©diaire d√®s r√©ception des chunks, sans attendre le traitement complet.

**Avantages** :

- Plugin peut continuer imm√©diatement avec le prochain batch
- R√©duit la latency per√ßue c√¥t√© client

**Impl√©mentation** :

```typescript
// Dans session-controller.ts
router.post('/session/:sessionId/notes/upload', async (req: Request, res: Response) => {
  const parsed = UploadSessionNotesBodyDto.safeParse(req.body);
  if (!parsed.success) {
    return res.status(400).json({ status: 'invalid_payload' });
  }

  // R√©pondre imm√©diatement "accepted"
  res.status(202).json({
    sessionId: req.params.sessionId,
    status: 'accepted',
    notes: parsed.data.notes.length,
  });

  // Traiter en arri√®re-plan (fire-and-forget)
  const command: UploadNotesCommand = { ... };
  notePublicationHandler.handle(command)
    .then(result => {
      routeLogger?.debug('Notes published', { published: result.published });
    })
    .catch(err => {
      routeLogger?.error('Error while publishing notes', { err });
    });
});
```

**Probl√®me** : Comment g√©rer les erreurs ? Le plugin ne saura pas si un batch a √©chou√©.

**Solution hybride** :

- Garder le statut 200 (synchrone) pour valider que les donn√©es sont re√ßues correctement
- Traiter en arri√®re-plan avec un worker pool
- Exposer un endpoint `/session/:sessionId/status` pour v√©rifier l'√©tat du traitement

**Impact estim√©** :

- R√©duction de latency per√ßue : **oui**
- R√©duction de dur√©e totale : **non** (m√™me dur√©e, juste d√©cal√©e)

---

### Solution 4 : Worker pool c√¥t√© API (IMPACT MOYEN)

**Principe** : D√©l√©guer le traitement des notes √† un pool de workers (threads ou child processes).

**Avantages** :

- Parall√©lisation r√©elle multi-core (Node.js est single-threaded par d√©faut)
- √âvite de bloquer l'event loop principal
- Scaling horizontal si d√©ploy√© avec plusieurs instances

**Impl√©mentation** :

```typescript
// Utiliser `worker_threads` de Node.js
import { Worker } from 'worker_threads';

class NotesWorkerPool {
  private workers: Worker[] = [];

  constructor(private readonly poolSize: number = 4) {
    for (let i = 0; i < poolSize; i++) {
      this.workers.push(new Worker('./note-worker.js'));
    }
  }

  async processNote(note: PublishableNote): Promise<string> {
    // Round-robin dispatch
    const worker = this.workers[Math.floor(Math.random() * this.workers.length)];

    return new Promise((resolve, reject) => {
      worker.once('message', resolve);
      worker.once('error', reject);
      worker.postMessage({ type: 'render', note });
    });
  }
}
```

**Impact estim√©** :

- Avec 4 workers : Throughput x4 (si CPU-bound)
- R√©duit latency pour les requ√™tes concurrentes

**Complexit√©** :

- N√©cessite architecture worker (serialization/deserialization)
- Debugging plus complexe
- Overhead de communication inter-process

---

### Solution 5 : Optimisation du markdown rendering (IMPACT VARIABLE)

**Principe** : Profiler et optimiser le `markdownRenderer.render()` lui-m√™me.

**Pistes** :

1. **Cache de rendering** : Si une note n'a pas chang√©, r√©utiliser le HTML pr√©c√©dent
2. **Pr√©-compilation des templates** : Si le renderer utilise des templates (callouts, etc.)
3. **Streaming rendering** : Commencer √† √©crire le HTML avant la fin du rendering

**Localisation** :

- D√©pend de l'impl√©mentation concr√®te du `MarkdownRendererPort`
- Identifier via profiling quelle √©tape est la plus co√ªteuse

**Impact estim√©** :

- Variable selon l'impl√©mentation actuelle (besoin de profiling)
- Potentiellement **20-50% de gain** si rendering est le goulot principal

---

## Recommandations par priorit√©

### üî• Priorit√© HAUTE (quick wins)

**1. Upload parall√®le des batches (Solution 1)**

- **Effort** : Faible (utilise utilitaires existants)
- **Gain** : √âlev√© (~60% sur la phase d'upload)
- **Risque** : Faible (facile √† rollback si probl√®me)

**Impl√©mentation** :

- Modifier `NotesUploaderAdapter.upload()` pour utiliser `processWithControlledConcurrency`
- Ajouter un setting pour concurrency (default=3, configurable via env var `UPLOAD_CONCURRENCY`)
- Idem pour `AssetsUploaderAdapter`

### üü† Priorit√© MOYENNE (gains significatifs)

**2. Traitement parall√®le c√¥t√© API (Solution 2)**

- **Effort** : Moyen (refactor du handler)
- **Gain** : √âlev√© (~70% sur la phase de traitement)
- **Risque** : Moyen (besoin de tester la charge CPU/m√©moire)

**Impl√©mentation** :

- Refactor `UploadNotesHandler.handle()` avec `Promise.allSettled`
- Ajouter un limiter de concurrency (ex: 10 notes simultan√©es max)
- Utiliser `processWithControlledConcurrency` pour contr√¥ler la charge

**3. Profiling et optimisation du rendering (Solution 5)**

- **Effort** : Variable (d√©pend des findings)
- **Gain** : Variable (peut √™tre √©norme si le renderer est mal optimis√©)
- **Risque** : Faible (optimisations cibl√©es)

**Impl√©mentation** :

- Ajouter des spans performance pour chaque √©tape du rendering
- Identifier les regex co√ªteuses, les boucles inefficaces
- Impl√©menter un cache si pertinent

### üü¢ Priorit√© BASSE (nice-to-have)

**4. Worker pool (Solution 4)**

- **Effort** : √âlev√© (architecture complexe)
- **Gain** : Moyen-√©lev√© (si CPU-bound et multi-instances)
- **Risque** : √âlev√© (complexit√©, debugging)

**Quand le faire** :

- Si les solutions 1+2 ne suffisent pas
- Si le backend doit g√©rer plusieurs sessions simultan√©es

**5. Streaming de r√©ponse (Solution 3)**

- **Effort** : Moyen
- **Gain** : Faible (latency per√ßue, pas de gain r√©el)
- **Risque** : Moyen (gestion des erreurs asynchrones)

**Quand le faire** :

- Si les uploads deviennent tr√®s longs (>10s par batch)
- N√©cessite un syst√®me de monitoring de jobs

---

## Plan d'action sugg√©r√©

### Phase 1 : Quick wins (1-2 jours)

1. ‚úÖ Impl√©menter **upload parall√®le des batches** (Solution 1)
   - Notes et assets
   - Configurable via env var `UPLOAD_CONCURRENCY=3`
2. ‚úÖ Ajouter instrumentation performance pour l'API
   - Spans dans `UploadNotesHandler` pour chaque note
   - M√©triques : `note-rendering-time`, `note-save-time`, `batch-processing-time`

### Phase 2 : Optimisations backend (2-3 jours)

3. ‚öôÔ∏è Impl√©menter **traitement parall√®le API** (Solution 2)
   - Avec `processWithControlledConcurrency(notes, processNote, 10)`
   - Tester charge CPU/m√©moire avec gros batches
4. üîç Profiling du markdown renderer (Solution 5)
   - Identifier les goulots avec les spans ajout√©s
   - Optimiser les √©tapes les plus co√ªteuses

### Phase 3 : Advanced optimizations (si n√©cessaire)

5. üöÄ Worker pool (Solution 4) - uniquement si phases 1+2 insuffisantes
6. üì° Streaming de r√©ponse (Solution 3) - uniquement si uploads tr√®s longs

---

## M√©triques de succ√®s

**Baseline actuel** (√† mesurer avec un gros vault ~500 notes, 200 assets) :

- Upload notes : **~8-12 secondes**
- Upload assets : **~4-6 secondes**
- Dur√©e totale publishing : **~15-25 secondes**

**Cibles apr√®s optimisations** :

- Upload notes : **~3-5 secondes** (gain 60-70%)
- Upload assets : **~1-2 secondes** (gain 60-70%)
- Dur√©e totale publishing : **~6-10 secondes** (gain 60%)

**M√©triques √† surveiller** :

- CPU usage c√¥t√© backend (ne pas d√©passer 80% sustained)
- M√©moire backend (pas de leak sur chunk reassembly)
- Latency r√©seau (v√©rifier que la parall√©lisation n'augmente pas les timeouts)
- Taux d'erreur (pas de regression sur la fiabilit√©)

---

## Configuration recommand√©e

### Variables d'environnement

```bash
# Plugin (future impl√©mentation)
UPLOAD_CONCURRENCY=3           # Batches simultan√©s (notes + assets)

# Backend
NOTES_PROCESSING_CONCURRENCY=10  # Notes trait√©es simultan√©ment par batch
WORKER_POOL_SIZE=4              # (si worker pool impl√©ment√©)
CHUNK_CLEANUP_INTERVAL_MS=30000 # Nettoyage chunks plus fr√©quent
```

### Instrumentation

```typescript
// Ajouter dans perfTracker :
perfTracker.startSpan('upload-notes-parallel');
perfTracker.recordMetric('upload-concurrency', 3);
perfTracker.recordMetric('batches-uploaded-parallel', batchCount);
perfTracker.endSpan('upload-notes-parallel');

// C√¥t√© API :
perfTracker.startSpan('batch-processing');
perfTracker.recordMetric('notes-processed-parallel', notesCount);
perfTracker.endSpan('batch-processing');
```

---

## Conclusion

Les **Solutions 1 + 2** (upload parall√®le + traitement parall√®le API) sont les plus rentables en termes de **gain/effort**. Elles permettent de r√©duire la dur√©e totale de **~60%** avec un effort d'impl√©mentation raisonnable et un risque contr√¥l√©.

La **Solution 5** (profiling du renderer) est √† faire syst√©matiquement car elle peut r√©v√©ler des gains inattendus.

Les **Solutions 3 + 4** sont des optimisations avanc√©es √† r√©server pour des sc√©narios extr√™mes (vaults de milliers de notes, backend partag√© multi-utilisateurs).
