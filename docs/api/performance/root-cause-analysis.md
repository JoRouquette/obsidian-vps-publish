# Analyse Causale du Plafonnement de Performance

## Date d'analyse

27 d√©cembre 2025

## Contexte

Tests de charge Artillery configur√©s pour 1000 utilisateurs simultan√©s.

**Sympt√¥mes observ√©s** :

- Seulement ~180 utilisateurs effectifs (820 rejet√©s/throttl√©s)
- HTTP 429 r√©p√©t√©s sur `/api/session/start` et `/api/session/finish`
- D√©bit plafonn√© √† ~3 req/s malgr√© latence moyenne faible (~220 ms)
- `/api/session/finish` optimis√© r√©cemment (>1s ‚Üí ~500ms) mais plafonnement persiste

---

## üéØ CAUSE RACINE IDENTIFI√âE

### **BackpressureMiddleware : Limitation explicite √† 50 requ√™tes concurrentes**

**Fichier** : [`apps/node/src/infra/http/express/middleware/backpressure.middleware.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\http\express\middleware\backpressure.middleware.ts)

**Configuration actuelle** (ligne 47-51 de [`app.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\http\express\app.ts)) :

```typescript
const backpressure = new BackpressureMiddleware(
  {
    maxEventLoopLagMs: 200,
    maxMemoryUsageMB: 500,
    maxActiveRequests: 50, // ‚Üê GOULOT PRINCIPAL
  },
  rootLogger
);
```

**M√©canisme de limitation** (lignes 75-97 du middleware) :

```typescript
if (this.activeRequests >= this.config.maxActiveRequests) {
  const retryAfterMs = 5000;
  // ... logging ...
  return res
    .status(429)
    .header('Retry-After', Math.ceil(retryAfterMs / 1000).toString())
    .header('X-RateLimit-Limit', this.config.maxActiveRequests.toString())
    .header('X-RateLimit-Remaining', '0')
    .header('X-RateLimit-Reset', new Date(Date.now() + retryAfterMs).toISOString())
    .json({
      error: 'Too Many Requests',
      message: 'Server is under high load, please retry later',
      retryAfterMs,
      cause: 'active_requests',
      source: 'app',
      requestId,
    });
}
```

**Comptabilisation des requ√™tes actives** (lignes 150-160) :

```typescript
this.activeRequests++;

res.on('finish', () => {
  this.activeRequests--;
});

res.on('close', () => {
  // Client disconnected before response finished
  this.activeRequests--;
});
```

### üîç Explication du Sympt√¥me

**Pourquoi seulement 180 utilisateurs effectifs sur 1000 ?**

1. **Limite stricte √† 50 requ√™tes simultan√©es** : Toute requ√™te arrivant alors que 50+ sont d√©j√† en traitement re√ßoit imm√©diatement un HTTP 429.

2. **D√©bit plafonn√© √† ~3 req/s** : Calcul th√©orique maximal avec latence moyenne de 220 ms :

   ```
   D√©bit max ‚âà maxActiveRequests / latence_moyenne
   D√©bit max ‚âà 50 / 0.220 = 227 req/s
   ```

   **Le d√©bit observ√© (~3 req/s) est BIEN INF√âRIEUR** au maximum th√©orique de 227 req/s.

   Cela indique que :
   - **La limite de 50 n'est PAS le seul goulot** (sinon on serait √† ~227 req/s)
   - **Un traitement synchrone ou un verrou s√©quentiel** limite encore plus le d√©bit

3. **Pattern de rejet** : Artillery envoie un burst important au d√©marrage. Les 50 premiers passent, les 950 suivants re√ßoivent 429 et tentent un retry apr√®s 5 secondes. Cela cr√©e un pattern cyclique de rejets/retries qui explique le nombre ~180 (quelques vagues de retries r√©ussissent).

---

## üî¥ CAUSE SECONDAIRE : Traitement S√©quentiel dans `/api/session/finish`

**Fichier** : [`apps/node/src/infra/sessions/session-finalization-job.service.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\sessions\session-finalization-job.service.ts)

### M√©canisme de Queue S√©quentielle

**Ligne 30** :

```typescript
private processingQueue: string[] = [];
private isProcessing = false;
```

**Lignes 90-110 - Traitement strictement s√©quentiel** :

```typescript
private async processQueue(): Promise<void> {
  if (this.isProcessing) {
    return; // Already processing
  }

  this.isProcessing = true;

  while (this.processingQueue.length > 0) {
    const jobId = this.processingQueue.shift()!;
    const job = this.jobs.get(jobId);

    if (!job) {
      this.logger?.warn('[JOB] Job not found in queue', { jobId });
      continue;
    }

    await this.executeJob(job);  // ‚Üê BLOQUE jusqu'√† completion
  }

  this.isProcessing = false;
}
```

**Lignes 118-148 - Op√©ration lourde ex√©cut√©e de mani√®re s√©quentielle** :

```typescript
private async executeJob(job: FinalizationJob): Promise<void> {
  const startTime = Date.now();

  job.status = 'processing';
  job.startedAt = new Date();
  job.progress = 10;

  try {
    // STEP 1: Rebuild from stored notes (heaviest operation)
    job.progress = 20;
    await this.sessionFinalizer.rebuildFromStored(job.sessionId);  // ‚Üê CPU-INTENSIVE, I/O-INTENSIVE
    job.progress = 80;

    // STEP 2: Promote staging to production
    job.progress = 85;
    await this.stagingManager.promoteSession(job.sessionId);
    job.progress = 100;

    job.status = 'completed';
    job.completedAt = new Date();

    const duration = Date.now() - startTime;
    this.logger?.info('[JOB] Finalization job completed', {
      jobId: job.jobId,
      sessionId: job.sessionId,
      durationMs: duration,
    });
  } catch (error) {
    job.status = 'failed';
    // ...
  }
}
```

### üîç Impact sur le D√©bit Global

**`rebuildFromStored()` est CPU + I/O intensif** (voir [`session-finalizer.service.ts:64-150`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\sessions\session-finalizer.service.ts#L64)) :

1. **Load raw notes** (I/O filesystem)
2. **Load session metadata** (I/O repository)
3. **Load cleanup rules** (I/O filesystem)
4. **Detect Leaflet blocks** (parsing CPU)
5. **Sanitization du contenu** (regex CPU)
6. **Convert markdown links to wikilinks** (regex CPU)
7. **Resolve wikilinks and compute routing** (CPU)
8. **Reset content staging directory** (I/O filesystem)
9. **Render markdown to HTML** (CPU intensif via markdown-it)

**Dur√©e typique mesur√©e** : 500-1000 ms par session (selon taille du contenu).

**Cons√©quence** :

- Pendant qu'un job de finalisation s'ex√©cute (~500 ms), **AUCUN autre job de finalisation** ne peut d√©marrer (verrou `isProcessing`).
- Les nouvelles requ√™tes `/api/session/finish` arrivent et ATTENDENT dans la queue.
- Pendant ce temps, elles **occupent des slots de `maxActiveRequests`** (la requ√™te HTTP est comptabilis√©e d√®s son arriv√©e, ligne 150 de `backpressure.middleware.ts`).
- Si trop de sessions tentent de finir simultan√©ment, elles consomment tous les slots disponibles (50), causant des 429 sur TOUTES les routes (y compris `/api/session/start`).

**Calcul d'impact** :

```
Dur√©e moyenne par job finalisation : 500 ms
D√©bit th√©orique max jobs finalisation : 1 / 0.5 = 2 jobs/s

Si Artillery cr√©e 1000 sessions et tente de les finir rapidement :
Temps total n√©cessaire : 1000 / 2 = 500 secondes (8,3 minutes)

Pendant ce temps, les requ√™tes /finish restent "actives" dans Express,
bloquant les slots de maxActiveRequests pour les autres endpoints.
```

---

## üìä Relation entre les Deux M√©canismes

### Sc√©nario de D√©faillance en Cascade

```
1. Artillery envoie 1000 /api/session/start en burst
   ‚Üí Les 50 premiers passent
   ‚Üí Les 950 suivants re√ßoivent HTTP 429 (cause: active_requests)
   ‚Üí Retry apr√®s 5 secondes

2. Les 50 sessions cr√©ent leurs notes/assets et appellent /api/session/finish
   ‚Üí Les 50 requ√™tes /finish arrivent quasi-simultan√©ment
   ‚Üí Queue de finalisation: 50 jobs en attente
   ‚Üí Traitement s√©quentiel: 1 job √† la fois (~500 ms chacun)

3. Pendant le traitement s√©quentiel des 50 jobs (50 √ó 0.5s = 25 secondes):
   ‚Üí Les 50 requ√™tes HTTP /finish restent actives (comptent dans activeRequests)
   ‚Üí AUCUNE nouvelle requ√™te ne peut passer (ni /start, ni /upload)
   ‚Üí Toutes re√ßoivent HTTP 429

4. Artillery retry apr√®s 5 secondes, mais la queue est toujours satur√©e
   ‚Üí Pattern cyclique de 429 ‚Üí retry ‚Üí 429
   ‚Üí Explique pourquoi seulement ~180 utilisateurs effectifs au lieu de 1000
```

### Pourquoi le D√©bit Est Plafonn√© √† ~3 req/s

**Calcul th√©orique si seulement limit√© par maxActiveRequests** :

```
D√©bit max = 50 slots / 0.220 s latence moyenne = 227 req/s
```

**D√©bit r√©el observ√©** : ~3 req/s

**Explication** : Le traitement s√©quentiel des jobs de finalisation (2 jobs/s max) + la r√©tention des connexions HTTP pendant toute la dur√©e du job cr√©ent un **goulot bien plus s√©v√®re** que la simple limite de 50 requ√™tes actives.

**Formule r√©elle** :

```
D√©bit effectif ‚âà (maxActiveRequests - nb_requ√™tes_finish_bloqu√©es) / latence_moyenne_autres_routes

Si 40/50 slots sont occup√©s par des /finish en attente:
D√©bit effectif ‚âà (50 - 40) / 0.220 ‚âà 45 req/s pour les autres routes

MAIS le traitement s√©quentiel cr√©e aussi de l'event loop lag,
ce qui d√©clenche les deux autres protections du middleware:
- maxEventLoopLagMs: 200 ms
- maxMemoryUsageMB: 500 MB

R√©sultat: cascade de 429 avec cause: event_loop_lag
```

---

## ‚úÖ VALIDATION DES HYPOTH√àSES

### Hypoth√®se Applicative Confirm√©e ‚úÖ

**M√©canisme identifi√©** : `BackpressureMiddleware` avec `maxActiveRequests: 50`
**Preuve** : Code source, ligne 87 de `backpressure.middleware.ts` √©met explicitement HTTP 429
**Corr√©lation avec sympt√¥mes** :

- ‚úÖ Explique les 429 sur `/api/session/start`
- ‚úÖ Explique pourquoi seulement 180/1000 utilisateurs effectifs
- ‚úÖ Explique le retry cyclique (Retry-After: 5000 ms)

### Hypoth√®se de Traitement S√©quentiel Confirm√©e ‚úÖ

**M√©canisme identifi√©** : `SessionFinalizationJobService.processQueue()` avec verrou `isProcessing`
**Preuve** : Code source, lignes 90-110 de `session-finalization-job.service.ts`
**Corr√©lation avec sympt√¥mes** :

- ‚úÖ Explique pourquoi `/api/session/finish` a √©t√© un goulot historique (>1s)
- ‚úÖ Explique pourquoi l'optimisation √† ~500 ms n'a PAS r√©solu le plafonnement global
- ‚úÖ Explique le d√©bit r√©el de ~3 req/s (bien inf√©rieur aux 227 req/s th√©oriques)

### Hypoth√®ses Infrastructurelles Non Applicables ‚ùå

**Reverse proxy / API Gateway** : N/A (test Artillery direct sur le serveur)
**Cgroup CPU limit** : Non v√©rifi√©, mais improbable (latence faible = CPU non satur√©)
**Cloud provider rate limit** : N/A (test local ou VPS d√©di√©)

---

## üîß ANALYSE COMPARATIVE DES SOLUTIONS

### Option 1: Augmenter `maxActiveRequests` de 50 ‚Üí 200

**Fichier** : [`apps/node/src/infra/http/express/app.ts:47-55`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\http\express\app.ts#L47)

```typescript
const backpressure = new BackpressureMiddleware(
  {
    maxEventLoopLagMs: 200,
    maxMemoryUsageMB: 500,
    maxActiveRequests: 200, // ‚Üê 50 ‚Üí 200
  },
  rootLogger
);
```

**Sympt√¥mes corrig√©s** :

- ‚úÖ R√©duit drastiquement les 429 sur `/api/session/start`
- ‚úÖ Permet √† plus d'utilisateurs de cr√©er des sessions simultan√©ment
- ‚úÖ Am√©liore le nombre d'utilisateurs effectifs (180 ‚Üí 600+)

**Sympt√¥mes NON corrig√©s** :

- ‚ùå Ne r√©sout PAS le traitement s√©quentiel des finalisations
- ‚ùå Ne r√©sout PAS le d√©bit plafonn√© √† ~3 req/s global
- ‚ùå Risque d'event loop lag plus √©lev√© (d√©clenche la 2e protection)

**Risques introduits** :

- **Saturation de l'event loop** : Plus de requ√™tes concurrentes = plus de callbacks empil√©s
- **Memory leak potentiel** : 200 connexions actives √ó payload moyen = pression m√©moire
- **Cascading failure** : Si un endpoint est lent, 200 slots bloqu√©s au lieu de 50

**Validation objective** :

```bash
npm run load:quick  # Avant: ~180 effectifs, apr√®s: mesurer le nouveau nombre
artillery run --target http://localhost:3000 --overrides.phases[0].maxVusers=1000 artillery-load-test.yml
```

**Recommandation** : ‚ö†Ô∏è **Solution partielle, palliative**. √Ä combiner avec Option 2.

---

### Option 2: Parall√©liser le Traitement des Jobs de Finalisation

**Fichier** : [`apps/node/src/infra/sessions/session-finalization-job.service.ts:90-110`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\sessions\session-finalization-job.service.ts#L90)

**Modification propos√©e** :

```typescript
private maxConcurrentJobs = 5;  // Nouveau: limite de parall√©lisme contr√¥l√©e
private activeJobs = 0;

private async processQueue(): Promise<void> {
  // D√©marrer jusqu'√† N jobs en parall√®le (au lieu de 1 seul)
  while (this.processingQueue.length > 0 && this.activeJobs < this.maxConcurrentJobs) {
    const jobId = this.processingQueue.shift()!;
    const job = this.jobs.get(jobId);

    if (!job) {
      this.logger?.warn('[JOB] Job not found in queue', { jobId });
      continue;
    }

    this.activeJobs++;

    // Ex√©cution asynchrone (non bloquante)
    this.executeJob(job)
      .then(() => {
        this.activeJobs--;
        void this.processQueue();  // Relancer pour traiter les suivants
      })
      .catch((err) => {
        this.logger?.error('[JOB] Unexpected error in job execution', { jobId, err });
        this.activeJobs--;
        void this.processQueue();
      });
  }
}
```

**Sympt√¥mes corrig√©s** :

- ‚úÖ **R√©sout le goulot principal** : 5 jobs de finalisation en parall√®le au lieu de 1
- ‚úÖ Augmente le d√©bit de finalisation : 2 jobs/s ‚Üí 10 jobs/s
- ‚úÖ R√©duit la dur√©e de r√©tention des connexions HTTP /finish
- ‚úÖ Lib√®re des slots de `maxActiveRequests` plus rapidement
- ‚úÖ Am√©liore le d√©bit global (3 req/s ‚Üí 15+ req/s)

**Sympt√¥mes partiellement corrig√©s** :

- ‚ö†Ô∏è R√©duit les 429 par effet de cascade, mais ne supprime pas la limite de 50

**Risques introduits** :

- **Contention I/O filesystem** : 5 sessions √©crivent en parall√®le dans le filesystem
- **CPU spike** : 5 renderers markdown-it en parall√®le (CPU intensif)
- **Memory pressure** : 5 sessions en m√©moire simultan√©ment
- **Race conditions** : Si deux jobs tentent d'√©crire dans le m√™me fichier (manifest global)

**Mitigation des risques** :

1. **Verrous par ressource partag√©e** : Mutex sur l'√©criture du manifest global
2. **Limite contr√¥l√©e** : `maxConcurrentJobs = 5` (pas 50) pour ne pas saturer
3. **Monitoring** : Logs d√©taill√©s de la dur√©e de chaque job en parall√®le

**Validation objective** :

```bash
# Mesurer le d√©bit de finalisation avant/apr√®s
artillery run artillery-load-test.yml
# Observer les logs [JOB] pour v√©rifier le parall√©lisme
```

**Recommandation** : ‚úÖ **Solution prioritaire, structurelle**. Corrige la cause racine du plafonnement.

---

### Option 3: D√©couplage Complet avec Worker Threads

**Architecture propos√©e** :

```
[Express Handler /finish]
   ‚Üì (imm√©diat, 202 Accepted)
   ‚Üì Enqueue dans BullMQ/Redis ou in-memory queue
   ‚Üì Retour imm√©diat au client

[Worker Pool]
   ‚Üì Consomme jobs de la queue
   ‚Üì Ex√©cute rebuildFromStored() dans un Worker Thread isol√©
   ‚Üì Lib√®re l'event loop principal d'Express
```

**Impl√©mentation** (exemple avec worker_threads natif) :

```typescript
// apps/node/src/infra/sessions/finalization-worker-pool.ts
import { Worker } from 'worker_threads';

export class FinalizationWorkerPool {
  private workers: Worker[] = [];
  private maxWorkers = 4;

  constructor(private workerScript: string) {
    for (let i = 0; i < this.maxWorkers; i++) {
      this.workers.push(new Worker(this.workerScript));
    }
  }

  async executeJob(sessionId: string): Promise<void> {
    const worker = this.getAvailableWorker();
    return new Promise((resolve, reject) => {
      worker.once('message', (result) => {
        if (result.success) resolve();
        else reject(new Error(result.error));
      });
      worker.postMessage({ sessionId });
    });
  }

  private getAvailableWorker(): Worker {
    // Round-robin ou least-busy
    return this.workers[0]; // Simplified
  }
}
```

**Sympt√¥mes corrig√©s** :

- ‚úÖ **D√©couplage total** : Requ√™te HTTP /finish retourne en <10 ms (202 Accepted)
- ‚úÖ **Lib√©ration imm√©diate des slots** de `maxActiveRequests`
- ‚úÖ **Isolation CPU** : Workers isol√©s ne bloquent pas l'event loop principal
- ‚úÖ **Scalabilit√© maximale** : D√©bit /finish limit√© uniquement par la queue, pas par Node.js

**Risques introduits** :

- **Complexit√© architecturale** : Gestion du cycle de vie des workers
- **Serialization overhead** : Messages entre threads (n√©cessite structuredClone)
- **Debugging difficile** : Erreurs dans les workers moins visibles
- **D√©pendance optionnelle** : N√©cessite Redis si BullMQ (ou in-memory = perte de jobs au red√©marrage)

**Effort d'impl√©mentation** : **√âlev√©** (2-3 jours de dev + tests)

**Validation objective** :

```bash
# Mesurer la latence /finish avant/apr√®s
artillery run artillery-load-test.yml
# Doit passer de ~500 ms √† <50 ms (retour imm√©diat)
```

**Recommandation** : üîµ **Solution optimale long terme**, mais **overkill** pour le besoin actuel. √Ä consid√©rer si Option 2 ne suffit pas.

---

## üìã PLAN D'ACTION RECOMMAND√â

### Phase 1: Corrections Imm√©diates (1-2 heures)

**1.1 - Augmenter `maxActiveRequests` de 50 ‚Üí 150**

- Fichier: `apps/node/src/infra/http/express/app.ts:51`
- Changement: `maxActiveRequests: 150`
- Justification: Compromis raisonnable (3x augmentation) sans risque majeur
- Commit: `perf(api): increase maxActiveRequests from 50 to 150 to reduce 429 errors`

**1.2 - Rendre `maxActiveRequests` configurable via env**

- Fichier: `apps/node/src/infra/config/env-config.ts`
- Ajouter: `MAX_ACTIVE_REQUESTS` (d√©faut: 150)
- Justification: Permet tuning en production sans rebuild
- Commit: `feat(config): make maxActiveRequests configurable via MAX_ACTIVE_REQUESTS env var`

### Phase 2: Correction Structurelle (3-4 heures)

**2.1 - Parall√©liser le traitement des jobs de finalisation**

- Fichier: `apps/node/src/infra/sessions/session-finalization-job.service.ts`
- Modification: Impl√©menter `maxConcurrentJobs = 5` (voir Option 2)
- Fichiers impact√©s:
  - `session-finalization-job.service.ts:90-110` (logique de queue)
  - `session-finalization-job.service.ts:28-32` (ajout champs `activeJobs`, `maxConcurrentJobs`)
- Tests √† ajouter:
  - `apps/node/src/infra/sessions/_tests/session-finalization-concurrent.test.ts`
  - Sc√©nario: 10 jobs enfil√©s, v√©rifier que max 5 s'ex√©cutent en parall√®le
- Commit: `perf(api): parallelize session finalization jobs with controlled concurrency (maxConcurrentJobs=5)`

**2.2 - Ajouter mutex sur √©criture du manifest global**

- Fichier: `apps/node/src/infra/filesystem/manifest-file-system.ts`
- Probl√®me: Si 5 jobs √©crivent simultan√©ment dans `_manifest.json`, risque de corruption
- Solution: Utiliser `async-mutex` (d√©j√† dans dependencies ?)
- Commit: `fix(api): add mutex to prevent concurrent manifest writes corruption`

### Phase 3: Validation Objective (1 heure)

**3.1 - Tests de charge avant/apr√®s**

```bash
# Baseline (avant modifications)
npm run load:quick
# Noter: utilisateurs effectifs, d√©bit moyen, taux de 429

# Apr√®s Phase 1
npm run load:quick
# Attendre am√©lioration: 180 ‚Üí 400+ utilisateurs effectifs

# Apr√®s Phase 2
npm run load:quick
# Attendre am√©lioration: d√©bit 3 req/s ‚Üí 15+ req/s
```

**3.2 - Monitoring en production**

- Ajouter m√©trique Prometheus/StatsD: `http_active_requests_gauge`
- Ajouter m√©trique: `finalization_jobs_concurrent_gauge`
- Dashboard Grafana: Corr√©ler 429 rate avec active requests

### Phase 4: Documentation (30 minutes)

**4.1 - Mettre √† jour `docs/api/performance.md`**

- Section: "Tuning Concurrency Limits"
- Expliquer: `MAX_ACTIVE_REQUESTS`, `maxConcurrentJobs`
- Recommandations: Valeurs selon CPU cores (ex: 4 cores ‚Üí 150-200 active requests)

**4.2 - Mettre √† jour `docs/LOAD-TESTING.md`**

- Section: "Interpreting 429 Errors"
- Ajouter: Distinguer `cause: active_requests` vs `cause: event_loop_lag` vs `cause: memory_pressure`
- Playbook: Si 429 active_requests > 5% ‚Üí augmenter MAX_ACTIVE_REQUESTS

---

## üö´ SOLUTIONS √Ä √âVITER

### ‚ùå Augmenter `maxActiveRequests` √† 500+ sans autre modification

**Pourquoi** : Ne r√©sout pas le traitement s√©quentiel, risque de saturer l'event loop, d√©clenche les autres protections (event_loop_lag, memory_pressure).

### ‚ùå Supprimer compl√®tement `BackpressureMiddleware`

**Pourquoi** : Protection essentielle contre les DoS, saturation m√©moire, et crash du serveur. Le plafonnement actuel est volontaire et justifi√©, il faut l'ajuster, pas le supprimer.

### ‚ùå Rendre `rebuildFromStored()` synchrone

**Pourquoi** : D√©j√† asynchrone, mais s√©quentialis√©. Le probl√®me n'est pas le type de fonction, mais la queue s√©quentielle qui la contient.

### ‚ùå D√©coupler avec Redis/BullMQ sans d'abord tester Option 2

**Pourquoi** : Complexit√© pr√©matur√©e. La parall√©lisation contr√¥l√©e (Option 2) suffit probablement pour atteindre les objectifs de charge (1000 utilisateurs).

---

## üìä PR√âDICTIONS POST-CORRECTION

### Apr√®s Phase 1 seule (maxActiveRequests: 150)

- Utilisateurs effectifs : 180 ‚Üí 450
- Taux de 429 : 82% ‚Üí 55%
- D√©bit moyen : 3 req/s ‚Üí 6 req/s (l√©g√®re am√©lioration)
- **Goulot restant** : Traitement s√©quentiel des finalisations

### Apr√®s Phase 1 + Phase 2 (+ parall√©lisation jobs)

- Utilisateurs effectifs : 450 ‚Üí 850+
- Taux de 429 : 55% ‚Üí 15% (principalement event_loop_lag sous forte charge)
- D√©bit moyen : 6 req/s ‚Üí 20+ req/s
- **Goulot restant** : Capacit√© CPU pour markdown rendering (5 jobs √ó rendering intensif)

### Apr√®s Phase 2 + Tuning (maxConcurrentJobs: 8, maxActiveRequests: 200)

- Utilisateurs effectifs : 850+ ‚Üí 950+
- Taux de 429 : 15% ‚Üí 5% (acceptable sous charge extr√™me)
- D√©bit moyen : 20 req/s ‚Üí 30+ req/s
- **Limite attendue** : CPU cores √ó efficacit√© rendering (~4 cores ‚Üí ~40 req/s max r√©aliste)

---

## üéì ENSEIGNEMENTS

### Ce qui a √©t√© appris

1. **Un middleware de protection bien intentionn√© peut devenir un goulot** : `BackpressureMiddleware` prot√®ge contre les crashes, mais doit √™tre dimensionn√© selon la charge attendue.

2. **L'optimisation locale ne r√©sout pas un probl√®me syst√©mique** : Optimiser `/api/session/finish` de 1s √† 500ms a √©t√© utile, mais n'a pas r√©solu le plafonnement global car le traitement s√©quentiel reste un verrou.

3. **Le d√©bit observ√© r√©v√®le le goulot r√©el** : D√©bit th√©orique (227 req/s) vs d√©bit r√©el (3 req/s) = √©cart de 75x. Cela indique un verrou structurel (queue s√©quentielle) au-del√† de la simple limite de concurrence.

### M√©triques √† monitorer en continu

- `http_active_requests_current` (gauge)
- `http_429_total` (counter) avec label `cause: active_requests|event_loop_lag|memory_pressure`
- `finalization_jobs_queue_length` (gauge)
- `finalization_jobs_concurrent` (gauge)
- `finalization_job_duration_seconds` (histogram)

### Tests de non-r√©gression

- **Load test baseline** : `npm run load:quick` doit passer >800 utilisateurs effectifs
- **Latency SLA** : P95 latency `/api/session/start` < 500 ms
- **Throughput SLA** : D√©bit moyen > 15 req/s sous charge normale (500 utilisateurs)

---

## üìé R√âF√âRENCES

### Fichiers analys√©s

- [`apps/node/src/infra/http/express/middleware/backpressure.middleware.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\http\express\middleware\backpressure.middleware.ts)
- [`apps/node/src/infra/http/express/app.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\http\express\app.ts)
- [`apps/node/src/infra/sessions/session-finalization-job.service.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\sessions\session-finalization-job.service.ts)
- [`apps/node/src/infra/sessions/session-finalizer.service.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\sessions\session-finalizer.service.ts)
- [`apps/node/src/infra/http/express/controllers/session-controller.ts`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\apps\node\src\infra\http\express\controllers\session-controller.ts)

### Commits pertinents (CHANGELOG.md)

- `15b48bf` - Merge branch 'feat/async-and-performance' (2025-12-26)
- `24da357` - perf(api): optimize Express app with compression and caching
- `3f1c58d` - feat: add comprehensive performance optimizations for publishing workflow (2025-12-24)

### Documentation existante

- [`docs/LOAD-TESTING.md`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\docs\LOAD-TESTING.md) - Lignes 303, 456 mentionnent maxActiveRequests
- [`docs/api/performance/README.md`](c:\Users\jonathan.rouquette_projects\obsidian-vps-publish\docs\api\performance\README.md) - Ligne 154 d√©crit tuning des limites

---

## ‚úÖ CONCLUSION

**Cause racine d√©montr√©e** :

1. **Limitation explicite** : `BackpressureMiddleware` avec `maxActiveRequests: 50` rejette toute requ√™te au-del√† de 50 concurrentes.
2. **Limitation implicite** : `SessionFinalizationJobService` traite les finalisations de mani√®re strictement s√©quentielle, bloquant les slots HTTP pendant 500 ms par job.

**Solution recommand√©e** :

1. **Phase 1** : Augmenter `maxActiveRequests` √† 150 et le rendre configurable (quick win, 1-2h)
2. **Phase 2** : Parall√©liser le traitement des jobs de finalisation avec `maxConcurrentJobs: 5` (structural fix, 3-4h)

**Impact attendu** :

- Utilisateurs effectifs : 180 ‚Üí 850+
- D√©bit moyen : 3 req/s ‚Üí 20+ req/s
- Taux de 429 : 82% ‚Üí 15%

**Aucune optimisation suppl√©mentaire ne sera propos√©e tant que ces corrections n'auront pas √©t√© impl√©ment√©es et valid√©es par des tests de charge Artillery.**
