# Load Testing avec Artillery - Un Seul Utilisateur

Ce guide explique comment exÃ©cuter des tests de montÃ©e en charge progressifs simulant **un seul utilisateur** qui envoie des publications de plus en plus volumineuses.

## Concept

Contrairement aux tests multi-utilisateurs, ce test simule un utilisateur unique qui :

- Commence avec de petites publications (10-20 notes)
- Augmente progressivement la taille des publications (50, 100, 200 notes)
- Atteint un pic avec de trÃ¨s grosses publications (500-1000 notes)
- Revient Ã  une charge normale

**Objectif** : Mesurer la capacitÃ© du systÃ¨me Ã  gÃ©rer des publications volumineuses d'un seul utilisateur, dÃ©tecter les seuils de backpressure, et vÃ©rifier la rÃ©cupÃ©ration.

## Installation

### PrÃ©requis

- Node.js 18+
- API backend en cours d'exÃ©cution (`npm run start node`)
- ClÃ© API valide

### Installer Artillery

```bash
# Global (recommandÃ©)
npm install -g artillery@latest

# Ou local au projet
npm install --save-dev artillery
```

## Configuration

### 1. CrÃ©er le fichier d'environnement

```bash
cp .env.artillery.example .env.artillery
```

### 2. Ã‰diter `.env.artillery`

```env
API_KEY=your-actual-api-key-here
```

**âš ï¸ CRITIQUE** :

- L'API_KEY est **OBLIGATOIRE** - sans elle, toutes les requÃªtes retourneront 401 (Unauthorized)
- Utilisez la mÃªme clÃ© que dans votre backend (variable `API_KEY` dans `.env.dev`)
- Ne commitez JAMAIS `.env.artillery` (dÃ©jÃ  dans `.gitignore`)

### 3. VÃ©rifier que le backend est lancÃ©

```bash
# Terminal 1: DÃ©marrer le backend
npm run start node

# VÃ©rifier que l'API rÃ©pond
curl -H "x-api-key: your-api-key" http://localhost:3000/api/health
# Doit retourner 200 OK
```

## ExÃ©cution des Tests

### âš ï¸ ProblÃ¨me Courant : 401 Unauthorized

**SymptÃ´me** : Tous les logs backend montrent `status:401` pour `/api/session/start`

**Cause** : L'API_KEY n'est pas chargÃ©e depuis `.env.artillery`

**Solution** : Utiliser les scripts npm qui chargent automatiquement `.env.artillery` :

```bash
# âœ… CORRECT - Utilise --dotenv .env.artillery automatiquement
npm run loadtest

# âœ… CORRECT - Avec rapport HTML auto-ouvert
npm run loadtest:report

# âŒ INCORRECT - Ne charge pas .env.artillery
artillery run artillery-load-test.yml
```

### Test Rapide (Dev)

```bash
# Charge lÃ©gÃ¨re pour dev (1 minute)
artillery quick --count 10 --num 100 http://localhost:3000/api/health
```

### Test Complet (MontÃ©e en Charge)

```bash
# Via npm script (recommandÃ© - charge .env.artillery automatiquement)
npm run loadtest

# Avec rapport HTML
npm run loadtest:report
```

### Test Manuel (si nÃ©cessaire)

```bash
# Charge explicitement .env.artillery
artillery run artillery-load-test.yml --dotenv .env.artillery

# Avec rapport HTML
artillery run --output report.json artillery-load-test.yml --dotenv .env.artillery && \
  artillery report report.json --output report.html && \
  npx open-cli report.html
```

### Test avec Target Custom

```bash
# Tester un serveur distant
API_KEY=your-key artillery run --target https://api.example.com artillery-load-test.yml
```

## Phases du Test

Le test suit 5 phases avec **1 seul utilisateur virtuel**, mais des **publications de plus en plus volumineuses** :

```
Phase 1: Warmup (60s)
  â””â”€ 10-20 notes par publication
  â””â”€ 5-10 assets
  â””â”€ 1 chunk par type
  â””â”€ Objectif: Ã‰tablir baseline

Phase 2: Ramp Up (2min)
  â””â”€ 50-100 notes par publication
  â””â”€ 20-40 assets
  â””â”€ 3-5 chunks pour notes, 2-4 pour assets
  â””â”€ Objectif: MontÃ©e progressive

Phase 3: Sustained Load (3min)
  â””â”€ 200-300 notes par publication
  â””â”€ 50-100 assets
  â””â”€ 10-15 chunks pour notes, 5-10 pour assets
  â””â”€ Objectif: Charge soutenue significative

Phase 4: Peak Load (2min)
  â””â”€ 500-1000 notes par publication ğŸ”¥
  â””â”€ 200-400 assets
  â””â”€ 25-50 chunks pour notes, 20-40 pour assets
  â””â”€ Objectif: Tester limites, dÃ©clencher backpressure

Phase 5: Cool Down (1min)
  â””â”€ 50-100 notes par publication
  â””â”€ 20-40 assets
  â””â”€ Retour Ã  charge normale
  â””â”€ Objectif: VÃ©rifier rÃ©cupÃ©ration
```

**DurÃ©e totale** : ~9 minutes  
**Utilisateurs simultanÃ©s** : 1 seul  
**Progression** : Volume des publications (notes + assets)

## ScÃ©nario TestÃ©

### Single User - Progressive Load (100% du trafic)

Simule un workflow complet de publication avec volume croissant :

1. **Calcul dynamique** : DÃ©termine le nombre de notes/assets selon la phase
2. **`POST /api/session/start`** : DÃ©marrer session avec `notesPlanned` et `assetsPlanned`
3. **`POST /api/session/{id}/notes/upload`** (boucle) : Upload notes en plusieurs chunks si nÃ©cessaire
4. **`POST /api/session/{id}/assets/upload`** (boucle) : Upload assets en plusieurs chunks
5. **`POST /api/session/{id}/finish`** : Finaliser session
6. **Pause** : 3-7 secondes avant prochaine publication

### 2. Health Check (20% du trafic)

```
GET /api/health
```

### 3. Ping API (10% du trafic)

```
GET /api/ping
```

## MÃ©triques CollectÃ©es

### MÃ©triques Standard Artillery

- **http.request_rate** : RequÃªtes/sec
- **http.response_time** : Latence (min/max/median/p95/p99)
- **http.responses** : Distribution codes HTTP (200, 429, 500, etc.)
- **http.codes.200** : SuccÃ¨s
- **http.codes.429** : Backpressure dÃ©clenchÃ© (NORMAL sous forte charge)
- **vusers.created** : Utilisateurs virtuels crÃ©Ã©s
- **vusers.completed** : ScÃ©narios complÃ©tÃ©s

### MÃ©triques PersonnalisÃ©es (artillery-processor.js)

- **batch.notesCount** : Nombre de notes par publication (histogram)
- **batch.assetsCount** : Nombre d'assets par publication (histogram)
- **batch.totalChunks** : Total de chunks envoyÃ©s par session
- **backpressure.triggered** : Nombre de 429 reÃ§us
- **backpressure.retryAfterMs** : Distribution des dÃ©lais de retry
- **session.started** : Sessions dÃ©marrÃ©es avec succÃ¨s
- **session.finished** : Sessions finalisÃ©es avec succÃ¨s
- **upload.success** : Uploads rÃ©ussis
- **upload.backpressure** : Uploads rejetÃ©s (429)
- **upload.failed** : Uploads Ã©chouÃ©s (autres erreurs)
- **request.slow** : RequÃªtes > 2s
- **scenario.duration** : DurÃ©e des scÃ©narios complets

**Logs en temps rÃ©el** :

```
[BATCH SIZE] Phase: Warmup | Notes: 15 | Assets: 7 | Chunks: 2
[BATCH SIZE] Phase: Peak | Notes: 847 | Assets: 312 | Chunks: 74
[BACKPRESSURE] /api/session/abc123/notes/upload returned 429 - retry after 5000ms
[SLOW REQUEST] /api/session/abc123/finish took 3245ms
```

## InterprÃ©ter les RÃ©sultats

### Rapport Console

```
Summary report @ 14:32:15(+0100)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Scenarios launched:  90  â† UN SEUL utilisateur, 90 publications
  Scenarios completed: 88
  Requests completed:  2340  â† Notes + assets + start/finish
  Mean response/sec:   26.14
  Response time (msec):
    min: 45
    max: 8230  â† Plus lent (grosses publications)
    median: 189
    p95: 1420
    p99: 4180
  Scenario counts:
    Single User - Progressive Load: 88 (100%)
  Codes:
    200: 2187
    429: 142 â† Backpressure dÃ©clenchÃ© en phase Peak (NORMAL)
    500: 11  â† Erreurs serveur (Ã€ INVESTIGUER)
  Custom metrics:
    batch.notesCount (p50): 127, (p95): 784, (p99): 978
    batch.assetsCount (p50): 51, (p95): 328, (p99): 389
    batch.totalChunks: 1847 chunks total
```

**InterprÃ©tation** :

- **1 seul utilisateur** a effectuÃ© 88 publications complÃ¨tes
- Les publications sont passÃ©es de ~15 notes (phase 1) Ã  ~800 notes (phase 4)
- Le backpressure s'est dÃ©clenchÃ© 142 fois, principalement en phase Peak (ATTENDU)

### Indicateurs de SantÃ©

âœ… **SUCCÃˆS** si :

- Taux d'erreurs 500 < 1%
- p95 < 2000ms (2s)
- p99 < 5000ms (5s)
- 429 uniquement pendant phase "Peak Load"
- Serveur rÃ©cupÃ¨re aprÃ¨s Cool Down

âš ï¸ **ATTENTION** si :

- p95 > 2000ms
- 429 dÃ¨s phase "Sustained Load"
- Taux d'erreurs 500 > 1%

âŒ **Ã‰CHEC** si :

- p95 > 5000ms
- Taux d'erreurs 500 > 5%
- Serveur ne rÃ©pond plus (timeouts)
- 429 dÃ¨s phase "Warmup"

### 429 (Backpressure) : Normal ou ProblÃ¨me ?

**Normal** :

- ApparaÃ®t uniquement en phase "Peak Load" (50 users/sec)
- `retryAfterMs` < 10s
- Taux 429 < 10% du total
- Logs montrent `[BACKPRESSURE]` warnings

**ProblÃ¨me** :

- 429 dÃ¨s phase "Sustained Load" (10 users/sec)
- `retryAfterMs` > 30s
- Taux 429 > 20%
- Serveur ne rÃ©cupÃ¨re pas aprÃ¨s Cool Down

**Action** : Ajuster seuils dans [backpressure.middleware.ts](../apps/node/src/infra/http/express/middleware/backpressure.middleware.ts) :

```typescript
{
  maxEventLoopLagMs: 200,  // Augmenter si 429 trop frÃ©quents
  maxMemoryUsageMB: 500,   // Augmenter si serveur a plus de RAM
  maxActiveRequests: 50,   // Augmenter si CPU supporte plus
}
```

## Rapport HTML

Le rapport HTML (`report.html`) contient :

- ğŸ“Š Graphiques latence vs temps
- ğŸ“ˆ Throughput (req/sec) vs temps
- ğŸ¯ Distribution codes HTTP
- ğŸ“‰ Percentiles (p50, p95, p99)
- â±ï¸ Timeline dÃ©taillÃ©e

**Exemple de graphique attendu** :

```
Latency (ms) over time (un seul utilisateur, volume croissant)
  â†‘
5000â”‚                                    â•±â•²  â† Peak: 500-1000 notes
4000â”‚                                â•±â•²â•±  â•²
3000â”‚                            â•±â•²â•±      â•²
2000â”‚                        â•±â•²â•±          â•²â•±â•²
1000â”‚              â•±â•²    â•±â•²â•±
 500â”‚      â”€â”€â”€â”€â•±â•²â”€â”€  â”€â”€â•±                    â”€â”€â”€â”€ â† Cool down
   0â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â†’
      Warmup  Ramp  Sustained  Peak    Cool
      10-20  50-100  200-300  500-1K  50-100 notes
                              â†‘
                         Backpressure
                         triggered
```

**Note** : La latence augmente avec le volume de donnÃ©es, pas avec le nombre d'utilisateurs.

### âš ï¸ Erreur Critique : "All requests return 401 Unauthorized"

**SymptÃ´me dans les logs backend** :

```
{"level":"info","message":"[PERF] Request completed","method":"POST","url":"/api/session/start","status":401,...}
{"level":"info","message":"[PERF] Request completed","method":"POST","url":"/api/session/start","status":401,...}
{"level":"info","message":"[PERF] Request completed","method":"POST","url":"/api/session/start","status":401,...}
```

**Cause** : L'API_KEY n'est pas transmise ou est incorrecte

**Solutions** :

1. **VÃ©rifier que `.env.artillery` existe et contient la bonne clÃ©** :

```bash
# VÃ©rifier le contenu
cat .env.artillery
# Doit afficher: API_KEY=votre-clÃ©-ici

# Copier depuis l'exemple si manquant
cp .env.artillery.example .env.artillery
# Ã‰diter avec votre vraie clÃ©
```

2. **Utiliser les scripts npm (recommandÃ©)** :

```bash
# âœ… CORRECT - Charge automatiquement .env.artillery
npm run loadtest

# âŒ INCORRECT - Ne charge PAS .env.artillery
artillery run artillery-load-test.yml
```

3. **VÃ©rifier que la clÃ© correspond au backend** :

```bash
# Comparer les deux fichiers
grep API_KEY .env.artillery
grep API_KEY .env.dev
# Les deux doivent avoir la MÃŠME valeur
```

4. **Test manuel de l'API_KEY** :

```bash
# Remplacer YOUR_KEY par votre vraie clÃ©
curl -H "x-api-key: YOUR_KEY" \
     -H "Content-Type: application/json" \
     -d '{"notesPlanned":5,"assetsPlanned":2}' \
     http://localhost:3000/api/session/start

# Doit retourner 200 avec {"sessionId":"..."}
# Si 401, votre API_KEY est incorrecte
```

5. **Tester Artillery avec variable inline** :

```bash
# Test direct avec clÃ© en dur (pour debug uniquement)
API_KEY=your-actual-key artillery run artillery-load-test.yml --dotenv .env.artillery

# Si Ã§a marche, le problÃ¨me est dans .env.artillery
```

### Erreur: "connect ECONNREFUSED"

**Cause** : Backend pas dÃ©marrÃ©

**Solution** :

```bash
npm run start node
# Attendre "Server listening on port 3000"
```

### Erreur: "401 Unauthorized" (avec backend qui rÃ©pond)

**Cause** : API_KEY invalide ou mal formatÃ©e dans `.env.artillery`

**Solution** :

```bash
# VÃ©rifier .env.artillery (pas d'espaces, pas de guillemets)
cat .env.artillery
# âœ… Correct: API_KEY=abc123xyz
# âŒ Incorrect: API_KEY = "abc123xyz"
# âŒ Incorrect: API_KEY='abc123xyz'

# VÃ©rifier backend .env
cat .env.dev  # ou .env.prod

# Les deux API_KEY doivent Ãªtre identiques
```

### Erreur: "Too many 500 errors"

**Cause** : Serveur sous-dimensionnÃ© ou bug

**Solution** :

1. VÃ©rifier logs backend : `npm run start node`
2. RÃ©duire charge : Ã©diter `artillery-load-test.yml` â†’ rÃ©duire `arrivalRate`
3. Profiler avec Chrome DevTools

### Backpressure ImmÃ©diat (429 dÃ¨s Warmup)

**Cause** : Seuils backpressure trop stricts OU problÃ¨me de performance

**Solution 1 - Assouplir les seuils** :

```typescript
// apps/node/src/infra/http/express/middleware/backpressure.middleware.ts
{
  maxEventLoopLagMs: 500,  // Assouplir
  maxMemoryUsageMB: 1000,
  maxActiveRequests: 100,
}
```

**Solution 2 - VÃ©rifier les optimisations** :

```bash
# Valider que toutes les optimisations sont actives
npm run perf:validate:strict
```

### Publications Ã‰chouent SystÃ©matiquement en Phase Peak

**Cause** : Volume trop Ã©levÃ© pour les capacitÃ©s actuelles

**Actions** :

1. RÃ©duire le pic : Ã‰diter `artillery-processor.js` â†’ Phase 4 Ã  300-500 notes au lieu de 500-1000
2. Augmenter concurrence plugin : `maxConcurrentUploads` dans settings Obsidian
3. Optimiser serveur : Plus de RAM, CPU plus rapide

## Scripts NPM

Ajouter Ã  `package.json` :

```json
{
  "scripts": {
    "loadtest": "export $(cat .env.artillery | xargs) && artillery run artillery-load-test.yml",
    "loadtest:report": "export $(cat .env.artillery | xargs) && artillery run --output report.json artillery-load-test.yml && artillery report report.json --output report.html && open report.html"
  }
}
```

Usage :

```bash
npm run loadtest
npm run loadtest:report
```

## IntÃ©gration CI (Optionnel)

Ajouter Ã  `.github/workflows/load-test.yml` :

```yaml
name: Load Test

on:
  workflow_dispatch: # Manuel
  schedule:
    - cron: '0 2 * * 0' # Chaque dimanche Ã  2h

jobs:
  load-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      - name: Start API server
        run: |
          npm run start node &
          sleep 10  # Attendre dÃ©marrage
        env:
          API_KEY: ${{ secrets.API_KEY }}

      - name: Install Artillery
        run: npm install -g artillery

      - name: Run load test
        run: |
          artillery run --output report.json artillery-load-test.yml
        env:
          API_KEY: ${{ secrets.API_KEY }}

      - name: Generate report
        if: always()
        run: artillery report report.json --output report.html

      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-test-report
          path: report.html
```

## RÃ©fÃ©rences

- [Artillery Documentation](https://www.artillery.io/docs)
- [Artillery Best Practices](https://www.artillery.io/docs/guides/guides/test-script-reference)
- [Performance Testing Guide](./api/performance-testing.md)
- [Performance Enhancements](./api/performance-enhancements.md)
- [Backpressure Middleware](../apps/node/src/infra/http/express/middleware/backpressure.middleware.ts)

## MÃ©triques Cibles (Un Seul Utilisateur)

| MÃ©trique             | Warmup (10-20) | Sustained (200-300) | Peak (500-1000) | Acceptable  |
| -------------------- | -------------- | ------------------- | --------------- | ----------- |
| p95 latency          | < 200ms        | < 1000ms            | < 3000ms        | < 5000ms    |
| p99 latency          | < 500ms        | < 2000ms            | < 8000ms        | < 15000ms   |
| Throughput           | > 5 req/s      | > 20 req/s          | > 15 req/s      | > 10 req/s  |
| Error rate (500)     | < 0.1%         | < 1%                | < 3%            | < 5%        |
| Backpressure (429)   | 0%             | < 2%                | < 15%           | < 30%       |
| Session success rate | 100%           | > 98%               | > 90%           | > 80%       |
| Memory growth        | Stable         | < 50MB/min          | < 100MB/min     | < 200MB/min |
| Event loop lag       | < 50ms         | < 150ms             | < 300ms         | < 500ms     |

**Note** : Ces cibles sont pour un seul utilisateur avec volume croissant. Les latences augmentent naturellement avec le volume de donnÃ©es Ã  traiter.

## Prochaines Ã‰tapes

| MÃ©trique           | Cible          | Acceptable  | Critique   |
| ------------------ | -------------- | ----------- | ---------- |
| p95 latency        | < 500ms        | < 2000ms    | > 5000ms   |
| p99 latency        | < 1000ms       | < 5000ms    | > 10000ms  |
| Throughput         | > 100 req/s    | > 50 req/s  | < 10 req/s |
| Error rate (500)   | < 0.1%         | < 1%        | > 5%       |
| Backpressure (429) | 0% (sustained) | < 5% (peak) | > 20%      |

## Prochaines Ã‰tapes

1. **Baseline** : ExÃ©cuter test initial pour Ã©tablir mÃ©triques de rÃ©fÃ©rence
2. **Optimiser** : Si mÃ©triques insuffisantes, ajuster code/config
3. **Automatiser** : IntÃ©grer dans CI pour dÃ©tection rÃ©gression
4. **Monitorer** : Collecter mÃ©triques en production (Prometheus/Grafana)
